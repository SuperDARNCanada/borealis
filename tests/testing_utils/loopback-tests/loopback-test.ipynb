{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOPBACK TESTER\n",
    "\n",
    "This notebook is useful for loopback tests when you have some Borealis data you would like to verify. This notebook is built off of the original test_beamforming.py script that I wrote in Nov/Dec 2018 to verify beamforming algorithms in Borealis. However, these analyses are useful to verify data after any update to the Borealis code. What follows is a list of functions that I plan to build into this script. - Marci Detwiller Feb 2019\n",
    "\n",
    "**If only release-mode data is available for a given time, this notebook will:**\n",
    "1. Plot the time domain data, or a portion of the data \n",
    "2. Verify location of the pulses in the data and pulse length\n",
    "3. Plot the frequency spectrum and find the peaks \n",
    "4. Verify the beamforming if output_samples_iq is available\n",
    "\n",
    "**If debug-mode data is available (rawrf, txdata, stage_1_iq, etc.), this notebook will also:**\n",
    "1. Verify the rawrf from the txdata\n",
    "2. Find the peaks of the FFT in the rawrf data and compare to the bfiq data to verify the decimation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import deepdish\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "sys.path.append(\"../plot_borealis_hdf5_data/\")\n",
    "\n",
    "from plotting_borealis_data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/radar/loopback_test_data/20220608.1546.00.sas.0.antennas_iq.hdf5.site\"\n",
    "data_file = os.path.basename(filename)\n",
    "data_directory = os.path.dirname(\n",
    "    filename\n",
    ")  # get directory outside of the data (/data/borealis_data)\n",
    "\n",
    "record_name = None  # or change if you want a specific record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the corresponding data files to this data file, including output_samples_iq, bfiq,\n",
    "# rawrf, txdata if available.\n",
    "\n",
    "data_file_metadata = data_file.split(\".\")\n",
    "\n",
    "date_of_file = data_file_metadata[0]\n",
    "timestamp_of_file = \".\".join(data_file_metadata[0:3])\n",
    "station_name = data_file_metadata[3]\n",
    "slice_id_number = data_file_metadata[4]\n",
    "\n",
    "file_suffix = data_file_metadata[-1]\n",
    "\n",
    "if file_suffix not in [\"hdf5\", \"site\"]:\n",
    "    raise Exception(\"Incorrect File Suffix: {}\".format(file_suffix))\n",
    "\n",
    "if file_suffix == \"hdf5\":\n",
    "    type_of_file = data_file_metadata[-2]  # XX.hdf5\n",
    "else:\n",
    "    type_of_file = data_file_metadata[-3]  # XX.hdf5.site\n",
    "\n",
    "if type_of_file == slice_id_number:\n",
    "    slice_id_number = \"0\"  # choose the first slice to search for other available files.\n",
    "else:\n",
    "    type_of_file = slice_id_number + \".\" + type_of_file\n",
    "\n",
    "\n",
    "antennas_iq_filetype = slice_id_number + \".antennas_iq\"\n",
    "bfiq_filetype = slice_id_number + \".bfiq\"\n",
    "stage_1_filetype = slice_id_number + \".stage_1_iq\"\n",
    "stage_2_filetype = slice_id_number + \".stage_2_iq\"\n",
    "stage_3_filetype = slice_id_number + \".stage_3_iq\"\n",
    "# stage 4 = output_samples_iq so unnecessary\n",
    "rawrf_filetype = \"rawrf\"\n",
    "tx_filetype = \"txdata\"\n",
    "output_samples_filetype = \"\"  # Added to remove exception further down\n",
    "file_types_avail = [\n",
    "    bfiq_filetype,\n",
    "    tx_filetype,\n",
    "    rawrf_filetype,\n",
    "    antennas_iq_filetype,\n",
    "    stage_1_filetype,\n",
    "    stage_2_filetype,\n",
    "    stage_3_filetype,\n",
    "]\n",
    "\n",
    "if type_of_file not in file_types_avail:\n",
    "    raise Exception(\n",
    "        \"Data type: {} not incorporated in script. Allowed types: {}\".format(\n",
    "            type_of_file, file_types_avail\n",
    "        )\n",
    "    )\n",
    "\n",
    "data = {}\n",
    "print(\"Available Filetypes: \")\n",
    "for file_type in list(\n",
    "    file_types_avail\n",
    "):  # copy of file_types_avail so we can modify it within.\n",
    "    try:\n",
    "        filename = (\n",
    "            data_directory\n",
    "            + \"/\"\n",
    "            + timestamp_of_file\n",
    "            + \".\"\n",
    "            + station_name\n",
    "            + \".\"\n",
    "            + file_type\n",
    "            + \".hdf5.site\"\n",
    "        )\n",
    "        data[file_type] = deepdish.io.load(filename)\n",
    "        print(file_type)\n",
    "    except:\n",
    "        file_types_avail.remove(file_type)\n",
    "        if file_type == type_of_file:  # if this is the filename you provided.\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a record from the provided file, and get that record for each filetype to analyze side by side.\n",
    "# Also reshaping data to correct dimensions - if there is a problem with reshaping, we will also not use that record.\n",
    "\n",
    "good_record_found = False\n",
    "record_attempts = 0\n",
    "while not good_record_found:\n",
    "    if record_name is None:\n",
    "        record_name = random.choice(list(data[type_of_file].keys()))\n",
    "    print(\"Record Name Chosen: {}\".format(record_name))\n",
    "    record_data = {}\n",
    "\n",
    "    try:\n",
    "        for file_type in file_types_avail:\n",
    "            record_data[file_type] = data[file_type][record_name]\n",
    "\n",
    "            if file_type == bfiq_filetype:\n",
    "                bf_iq = record_data[bfiq_filetype]\n",
    "\n",
    "            if file_type == output_samples_filetype:\n",
    "                output_samples_iq = record_data[output_samples_filetype]\n",
    "\n",
    "            if file_type == rawrf_filetype:\n",
    "                rawrf = record_data[rawrf_filetype]\n",
    "\n",
    "            # tx data does not need to be reshaped.\n",
    "            if file_type == tx_filetype:\n",
    "                tx = record_data[tx_filetype]\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(\n",
    "            \"Record {} raised an exception in filetype {}:\\n\".format(\n",
    "                record_name, file_type\n",
    "            )\n",
    "        )\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nA new record will be selected.\")\n",
    "        record_attempts += 1\n",
    "        if record_attempts == 3:\n",
    "            print(\"FILES FAILED WITH 3 FAILED ATTEMPTS TO LOAD RECORDS.\")\n",
    "            raise  # something is wrong with the files\n",
    "    else:  # no errors\n",
    "        good_record_found = True\n",
    "\n",
    "if bfiq_filetype not in file_types_avail:\n",
    "    raise Exception(\"BFIQ data is required to do tests and could not be loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(record_data[stage_1_filetype].keys())\n",
    "print(record_data[stage_1_filetype][\"data_descriptors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output_samples_iq_data(record_data[stage_1_filetype], stage_1_filetype)\n",
    "# plot_output_samples_iq_data(record_data[stage_2_filetype], stage_2_filetype)\n",
    "# plot_output_samples_iq_data(record_data[stage_3_filetype], stage_3_filetype)\n",
    "plot_antennas_iq_data(record_data[antennas_iq_filetype], antennas_iq_filetype)\n",
    "\n",
    "\n",
    "plot_bf_iq_data(record_data[bfiq_filetype], bfiq_filetype)\n",
    "\n",
    "# We should see pulses in loopback data. We should see only noise perhaps with some leakage\n",
    "# if a channel is not connected (i.e. intf channels in loopback tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(record_data[tx_filetype]['dm_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In loopback data, we expect to see the peak of the FFT at our transmitted frequency. We expect to see\n",
    "# other peaks at 666.6 Hz off of the txfreq, because this is the periodicity of our signal (1.5ms = tau)\n",
    "\n",
    "\n",
    "# fft_samps, xf, fig = fft_and_plot_bfiq_data(record_data[bfiq_filetype], 'bfiq')\n",
    "# fft_samps, xf, fig = fft_and_plot_output_samples_iq(record_data[output_samples_filetype], 'output_samples')\n",
    "# fft_samps, xf, fig = fft_and_plot_output_samples_iq(record_data[stage_1_filetype], 'stage 1', plot_width=50)\n",
    "# fft_samps, xf, fig = fft_and_plot_output_samples_iq(record_data[stage_2_filetype], 'stage 2', plot_width=100)\n",
    "# fft_samps, xf, fig = fft_and_plot_output_samples_iq(record_data[stage_3_filetype], 'stage 3')\n",
    "\n",
    "# fft_and_plot_rawrf_data(record_data[rawrf_filetype], 'rawrf', plot_width=20000, start_sample=0, end_sample=-1, center=-500000)\n",
    "# fft_and_plot_txdata(record_data[tx_filetype], 'txdata')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(record_data[antennas_iq_filetype][\"rx_sample_rate\"])\n",
    "fft_samps, xf, fig = fft_and_plot_antennas_iq(\n",
    "    record_data[antennas_iq_filetype], \"antennas_iq\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
